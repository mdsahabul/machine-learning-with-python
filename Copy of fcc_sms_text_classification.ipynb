{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8RZOuS9LWQvv"},"outputs":[],"source":["# import libraries\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  !pip install tf-nightly\n","except Exception:\n","  pass\n","import tensorflow as tf\n","import pandas as pd\n","from tensorflow import keras\n","!pip install tensorflow-datasets\n","import tensorflow_datasets as tfds\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMHwYXHXCar3"},"outputs":[],"source":["# get data files\n","TRAIN_DATA_URL = \"https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/train-data.tsv\"\n","TEST_DATA_URL = \"https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/valid-data.tsv\"\n","\n","train_file_path = tf.keras.utils.get_file(\"train-data.tsv\", TRAIN_DATA_URL)\n","test_file_path = tf.keras.utils.get_file(\"valid-data.tsv\", TEST_DATA_URL)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_h508FEClxO"},"outputs":[],"source":["# Make numpy values easier to read.\n","np.set_printoptions(precision=3, suppress=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOMKywn4zReN"},"outputs":[],"source":["!head {train_file_path}\n","header_list = [\"sms_class\", \"message\"]\n","df_train = pd.read_csv(train_file_path, delimiter='\\t', quoting=3, names=header_list)\n","df_test = pd.read_csv(test_file_path, delimiter='\\t', quoting=3, names=header_list)\n","df_train = df_train[['message', 'sms_class']]\n","df_test = df_test[['message', 'sms_class']]\n","# Replacing string values to numbers\n","df_train['sms_class'] = df_train['sms_class'].apply({'ham':0, 'spam':1}.get) \n","df_test['sms_class'] = df_test['sms_class'].apply({'ham':0, 'spam':1}.get) \n","# Cleaning the texts in the training set\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","corpus_train = []\n","for i in range(0, 4179):\n","    review = re.sub('[^a-zA-Z0-9]', ' ', df_train['message'][i])\n","    review = review.lower()\n","    review = review.split()\n","    ps = PorterStemmer()\n","    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n","    review = ' '.join(review)\n","    corpus_train.append(review)\n","# Cleaning the texts in the test set\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","corpus_test = []\n","for i in range(0, 1392):\n","    review = re.sub('[^a-zA-Z0-9]', ' ', df_test['message'][i])\n","    review = review.lower()\n","    review = review.split()\n","    ps = PorterStemmer()\n","    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n","    review = ' '.join(review)\n","    corpus_test.append(review)\n","from keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(corpus_train)\n","\n","X_train = tokenizer.texts_to_sequences(corpus_train)\n","X_test = tokenizer.texts_to_sequences(corpus_test)\n","\n","vocab_size = len(tokenizer.word_index) + 1  \n","# Adding 1 because of reserved 0 index\n","\n","print(corpus_train[2])\n","print(X_train[2])\n","from keras.models import Sequential\n","from keras import layers\n","\n","embedding_dim = 50\n","\n","model = Sequential()\n","model.add(layers.Embedding(input_dim=vocab_size, \n","                           output_dim=embedding_dim, \n","                           input_length=maxlen))\n","model.add(layers.Conv1D(128, 5, activation='relu'))\n","model.add(layers.GlobalMaxPool1D())\n","model.add(layers.Dense(10, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model.summary()\n","history = model.fit(X_train, y_train,\n","                    epochs=10,\n","                    verbose=True,\n","                    validation_data=(X_test, y_test),\n","                    batch_size=10)\n","loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n","print(\"Training Accuracy: {:.4f}\".format(accuracy))\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n","print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9tD9yACG6M9"},"outputs":[],"source":["# function to predict messages based on model\n","# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n","def predict_message(pred_text):\n","\n","\n","\n","  return (prediction)\n","\n","pred_text = \"how are you doing today?\"\n","\n","prediction = predict_message(pred_text)\n","print(prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dxotov85SjsC"},"outputs":[],"source":["# Run this cell to test your function and model. Do not modify contents.\n","def test_predictions():\n","  test_messages = [\"how are you doing today\",\n","                   \"sale today! to stop texts call 98912460324\",\n","                   \"i dont want to go. can we try it a different day? available sat\",\n","                   \"our new mobile video service is live. just install on your phone to start watching.\",\n","                   \"you have won Â£1000 cash! call to claim your prize.\",\n","                   \"i'll bring it tomorrow. don't forget the milk.\",\n","                   \"wow, is your arm alright. that happened to me one time too\"\n","                  ]\n","\n","  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n","  passed = True\n","\n","  for msg, ans in zip(test_messages, test_answers):\n","    prediction = predict_message(msg)\n","    if prediction[1] != ans:\n","      passed = False\n","\n","  if passed:\n","    print(\"You passed the challenge. Great job!\")\n","  else:\n","    print(\"You haven't passed yet. Keep trying.\")\n","\n","test_predictions()\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"fcc_sms_text_classification.ipynb","private_outputs":true,"provenance":[{"file_id":"https://github.com/freeCodeCamp/boilerplate-neural-network-sms-text-classifier/blob/master/fcc_sms_text_classification.ipynb","timestamp":1668105454439}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{}},"nbformat":4,"nbformat_minor":0}